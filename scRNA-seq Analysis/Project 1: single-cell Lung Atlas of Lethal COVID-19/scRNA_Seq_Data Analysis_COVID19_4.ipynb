{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data came from https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE171524 --> GSE171524_RAW.tar file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only necessary if you are runing an analysis with multiple samples. The experiment sampled 19 COVID-19 patients and 7 control patients. There are a total of 26 samples in this analysis, thus, integration is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are essentially gonna now do the same thing as we did for (1) loading the data, (2) doublet removal, (3) preprocessing, and (4) Clustering.\n",
    "However, we will do this for all samples, to make this more efficient, we made this into a function and have the function iterate through each sample file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc  # Import garbage collector\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def pp(csv_path):\n",
    "    adata = sc.read_csv(csv_path).T\n",
    "    sc.pp.filter_genes(adata, min_cells=10)\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=2000, subset=True, flavor='seurat_v3')\n",
    "    scvi.model.SCVI.setup_anndata(adata)\n",
    "    vae = scvi.model.SCVI(adata)\n",
    "    vae.train()\n",
    "    solo = scvi.external.SOLO.from_scvi_model(vae)\n",
    "    solo.train()\n",
    "    df = solo.predict()\n",
    "    df['prediction'] = solo.predict(soft=False)\n",
    "    df.index = df.index.map(lambda x: x[:-2])\n",
    "    df['dif'] = df.doublet - df.singlet\n",
    "    doublets = df[(df.prediction == 'doublet') & (df.dif > 0.25)]\n",
    "    \n",
    "    adata = sc.read_csv(csv_path).T\n",
    "    adata.obs['Sample'] = csv_path.split('_')[2]\n",
    "    adata.obs['doublet'] = adata.obs.index.isin(doublets.index)\n",
    "    adata = adata[~adata.obs.doublet]\n",
    "    \n",
    "    sc.pp.filter_cells(adata, min_genes=200)\n",
    "    adata.var['mt'] = adata.var_names.str.startswith('mt-')\n",
    "    \n",
    "    ribo_url = \"http://software.broadinstitute.org/gsea/msigdb/download_geneset.jsp?geneSetName=KEGG_RIBOSOME&fileType=txt\"\n",
    "    ribo_genes = pd.read_table(ribo_url, skiprows=2, header=None)\n",
    "    adata.var['ribo'] = adata.var_names.isin(ribo_genes[0].values)\n",
    "    \n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True)\n",
    "    \n",
    "    upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98)\n",
    "    adata = adata[adata.obs.n_genes_by_counts < upper_lim]\n",
    "    adata = adata[adata.obs.pct_counts_mt < 20]\n",
    "    adata = adata[adata.obs.pct_counts_ribo < 2]\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def batch_process(input_dir, output_dir, batch_size=2):  # Reduce batch size to 2\n",
    "    files = os.listdir(input_dir)\n",
    "    batches = [files[i:i + batch_size] for i in range(0, len(files), batch_size)]\n",
    "    \n",
    "    for i, batch in enumerate(batches):\n",
    "        out = []\n",
    "        for file in batch:\n",
    "            file_path = os.path.join(input_dir, file)\n",
    "            out.append(pp(file_path))\n",
    "        \n",
    "        batch_adata = sc.concat(out)\n",
    "        batch_adata.write(os.path.join(output_dir, f'batch_{i}.h5ad'))\n",
    "        print(f'Processed batch {i} and saved to disk.')\n",
    "        \n",
    "        del out, batch_adata  # Clear variables to free memory\n",
    "        gc.collect()  # Force garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [15:05<00:00,  2.23s/it, v_num=1, train_loss_step=331, train_loss_epoch=323]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [15:06<00:00,  2.27s/it, v_num=1, train_loss_step=331, train_loss_epoch=323]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/400:  42%|████▏     | 167/400 [01:02<01:26,  2.68it/s, v_num=1, train_loss_step=0.316, train_loss_epoch=0.3]  \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.285. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [11:13<00:00,  1.71s/it, v_num=1, train_loss_step=405, train_loss_epoch=396]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [11:13<00:00,  1.68s/it, v_num=1, train_loss_step=405, train_loss_epoch=396]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/400:  36%|███▌      | 143/400 [00:40<01:13,  3.51it/s, v_num=1, train_loss_step=0.357, train_loss_epoch=0.306] \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.281. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 0 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [17:35<00:00,  2.61s/it, v_num=1, train_loss_step=389, train_loss_epoch=331]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [17:35<00:00,  2.64s/it, v_num=1, train_loss_step=389, train_loss_epoch=331]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/400:  76%|███████▌  | 303/400 [02:08<00:41,  2.36it/s, v_num=1, train_loss_step=0.562, train_loss_epoch=0.31] \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.292. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [10:50<00:00,  1.61s/it, v_num=1, train_loss_step=295, train_loss_epoch=308]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [10:50<00:00,  1.63s/it, v_num=1, train_loss_step=295, train_loss_epoch=308]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/400:  41%|████      | 163/400 [00:43<01:03,  3.73it/s, v_num=1, train_loss_step=0.195, train_loss_epoch=0.247]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.237. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [14:06<00:00,  2.12s/it, v_num=1, train_loss_step=311, train_loss_epoch=305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [14:06<00:00,  2.12s/it, v_num=1, train_loss_step=311, train_loss_epoch=305]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/400:  39%|███▉      | 155/400 [00:53<01:24,  2.89it/s, v_num=1, train_loss_step=0.224, train_loss_epoch=0.228]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.247. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [10:08<00:00,  1.52s/it, v_num=1, train_loss_step=330, train_loss_epoch=326]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [10:08<00:00,  1.52s/it, v_num=1, train_loss_step=330, train_loss_epoch=326]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/400:  58%|█████▊    | 231/400 [00:58<00:42,  3.98it/s, v_num=1, train_loss_step=0.219, train_loss_epoch=0.255] \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.247. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 2 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [11:45<00:00,  1.76s/it, v_num=1, train_loss_step=291, train_loss_epoch=288]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [11:45<00:00,  1.76s/it, v_num=1, train_loss_step=291, train_loss_epoch=288]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/400:  61%|██████    | 243/400 [01:10<00:45,  3.43it/s, v_num=1, train_loss_step=0.0697, train_loss_epoch=0.251]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.250. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [07:34<00:00,  1.15s/it, v_num=1, train_loss_step=397, train_loss_epoch=332]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [07:34<00:00,  1.14s/it, v_num=1, train_loss_step=397, train_loss_epoch=332]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/400:  52%|█████▏    | 208/400 [00:39<00:36,  5.24it/s, v_num=1, train_loss_step=0.204, train_loss_epoch=0.272]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.297. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 3 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [12:28<00:00,  1.88s/it, v_num=1, train_loss_step=537, train_loss_epoch=473]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [12:28<00:00,  1.87s/it, v_num=1, train_loss_step=537, train_loss_epoch=473]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/400:  54%|█████▍    | 215/400 [01:05<00:56,  3.28it/s, v_num=1, train_loss_step=0.302, train_loss_epoch=0.352]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.358. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [09:01<00:00,  1.34s/it, v_num=1, train_loss_step=260, train_loss_epoch=259]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [09:01<00:00,  1.35s/it, v_num=1, train_loss_step=260, train_loss_epoch=259]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/400:  50%|█████     | 202/400 [00:44<00:43,  4.51it/s, v_num=1, train_loss_step=0.315, train_loss_epoch=0.275]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.292. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 4 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [07:30<00:00,  1.13s/it, v_num=1, train_loss_step=341, train_loss_epoch=344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [07:30<00:00,  1.13s/it, v_num=1, train_loss_step=341, train_loss_epoch=344]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/400:  68%|██████▊   | 273/400 [00:53<00:24,  5.14it/s, v_num=1, train_loss_step=0.467, train_loss_epoch=0.319]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.325. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [18:53<00:00,  2.79s/it, v_num=1, train_loss_step=350, train_loss_epoch=361]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [18:53<00:00,  2.83s/it, v_num=1, train_loss_step=350, train_loss_epoch=361]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/400:  45%|████▌     | 180/400 [01:21<01:39,  2.22it/s, v_num=1, train_loss_step=0.376, train_loss_epoch=0.299]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.284. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 5 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [12:35<00:00,  1.87s/it, v_num=1, train_loss_step=391, train_loss_epoch=339]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [12:35<00:00,  1.89s/it, v_num=1, train_loss_step=391, train_loss_epoch=339]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/400:  75%|███████▍  | 299/400 [01:32<00:31,  3.25it/s, v_num=1, train_loss_step=0.474, train_loss_epoch=0.355] \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.318. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [10:18<00:00,  1.54s/it, v_num=1, train_loss_step=371, train_loss_epoch=341]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [10:18<00:00,  1.55s/it, v_num=1, train_loss_step=371, train_loss_epoch=341]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/400:  57%|█████▊    | 230/400 [00:58<00:42,  3.96it/s, v_num=1, train_loss_step=0.293, train_loss_epoch=0.285]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.281. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 6 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [08:52<00:00,  1.34s/it, v_num=1, train_loss_step=342, train_loss_epoch=339]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [08:52<00:00,  1.33s/it, v_num=1, train_loss_step=342, train_loss_epoch=339]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/400:  45%|████▌     | 180/400 [00:40<00:49,  4.41it/s, v_num=1, train_loss_step=0.391, train_loss_epoch=0.253] \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.247. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [03:51<00:00,  1.76it/s, v_num=1, train_loss_step=316, train_loss_epoch=310]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [03:51<00:00,  1.73it/s, v_num=1, train_loss_step=316, train_loss_epoch=310]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/400:  54%|█████▍    | 217/400 [00:21<00:18,  9.87it/s, v_num=1, train_loss_step=0.286, train_loss_epoch=0.286]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.296. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 7 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [08:06<00:00,  1.24s/it, v_num=1, train_loss_step=266, train_loss_epoch=356]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [08:06<00:00,  1.22s/it, v_num=1, train_loss_step=266, train_loss_epoch=356]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/400:  64%|██████▍   | 256/400 [00:52<00:29,  4.92it/s, v_num=1, train_loss_step=0.327, train_loss_epoch=0.343]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.336. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [09:32<00:00,  1.53s/it, v_num=1, train_loss_step=320, train_loss_epoch=318]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [09:32<00:00,  1.43s/it, v_num=1, train_loss_step=320, train_loss_epoch=318]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 226/400:  56%|█████▋    | 226/400 [00:53<00:41,  4.23it/s, v_num=1, train_loss_step=0.4, train_loss_epoch=0.317]  \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.327. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 8 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [11:56<00:00,  1.80s/it, v_num=1, train_loss_step=437, train_loss_epoch=370]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [11:56<00:00,  1.79s/it, v_num=1, train_loss_step=437, train_loss_epoch=370]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/400:  74%|███████▍  | 295/400 [01:31<00:32,  3.23it/s, v_num=1, train_loss_step=0.299, train_loss_epoch=0.298]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.290. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [10:02<00:00,  1.49s/it, v_num=1, train_loss_step=308, train_loss_epoch=353]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [10:02<00:00,  1.51s/it, v_num=1, train_loss_step=308, train_loss_epoch=353]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/400:  30%|███       | 122/400 [00:30<01:08,  4.04it/s, v_num=1, train_loss_step=0.284, train_loss_epoch=0.295]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.300. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 9 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [04:28<00:00,  1.50it/s, v_num=1, train_loss_step=402, train_loss_epoch=381]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [04:28<00:00,  1.49it/s, v_num=1, train_loss_step=402, train_loss_epoch=381]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/400:  78%|███████▊  | 313/400 [00:36<00:10,  8.51it/s, v_num=1, train_loss_step=0.36, train_loss_epoch=0.29]  \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.302. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [11:24<00:00,  1.71s/it, v_num=1, train_loss_step=321, train_loss_epoch=339]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [11:24<00:00,  1.71s/it, v_num=1, train_loss_step=321, train_loss_epoch=339]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/400:  55%|█████▍    | 219/400 [01:02<00:51,  3.52it/s, v_num=1, train_loss_step=0.235, train_loss_epoch=0.266] \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.245. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 10 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [06:55<00:00,  1.10s/it, v_num=1, train_loss_step=303, train_loss_epoch=304]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [06:55<00:00,  1.04s/it, v_num=1, train_loss_step=303, train_loss_epoch=304]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/400:  82%|████████▎ | 330/400 [00:58<00:12,  5.60it/s, v_num=1, train_loss_step=0.162, train_loss_epoch=0.186] \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.212. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [06:10<00:00,  1.09it/s, v_num=1, train_loss_step=383, train_loss_epoch=417]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [06:10<00:00,  1.08it/s, v_num=1, train_loss_step=383, train_loss_epoch=417]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/400:  53%|█████▎    | 213/400 [00:33<00:29,  6.39it/s, v_num=1, train_loss_step=0.356, train_loss_epoch=0.351]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.345. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 11 and saved to disk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [08:28<00:00,  1.27s/it, v_num=1, train_loss_step=319, train_loss_epoch=322]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [08:28<00:00,  1.27s/it, v_num=1, train_loss_step=319, train_loss_epoch=322]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/400:  57%|█████▋    | 227/400 [00:47<00:36,  4.73it/s, v_num=1, train_loss_step=0.439, train_loss_epoch=0.292] \n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.283. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [17:18<00:00,  2.60s/it, v_num=1, train_loss_step=319, train_loss_epoch=341]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=400` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400: 100%|██████████| 400/400 [17:18<00:00,  2.60s/it, v_num=1, train_loss_step=319, train_loss_epoch=341]\n",
      "\u001b[34mINFO    \u001b[0m Creating doublets, preparing SOLO model.                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/400:  43%|████▎     | 172/400 [01:11<01:34,  2.41it/s, v_num=1, train_loss_step=0.223, train_loss_epoch=0.314]\n",
      "Monitored metric validation_loss did not improve in the last 30 records. Best score: 0.293. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116: UserWarning: Prior to scvi-tools 1.1.3, `SOLO.predict` with `soft=True` (the default option) returned logits instead of probabilities. This behavior has since been corrected to return probabiltiies. The previous behavior can be replicated by passing in `return_logits=True`.\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\preprocessing\\_simple.py:166: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"n_genes\"] = number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 12 and saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Set your directories and batch size\n",
    "input_dir = 'GSE171524_RAW/'\n",
    "output_dir = 'D:/processed_batches/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Run batch processing with reduced batch size\n",
    "batch_process(input_dir, output_dir, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.24 GiB for an array with shape (9647, 34546) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Later, you can concatenate the batches\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m batches \u001b[38;5;241m=\u001b[39m [\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(output_dir) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5ad\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      3\u001b[0m adata \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mconcat(batches)\n\u001b[0;32m      4\u001b[0m sc\u001b[38;5;241m.\u001b[39mpp\u001b[38;5;241m.\u001b[39mfilter_genes(adata, min_cells\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\legacy_api_wrap\\__init__.py:80\u001b[0m, in \u001b[0;36mlegacy_api.<locals>.wrapper.<locals>.fn_compatible\u001b[1;34m(*args_all, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_compatible\u001b[39m(\u001b[38;5;241m*\u001b[39margs_all: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m R:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_all) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_positional:\n\u001b[1;32m---> 80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     args_pos: P\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m     83\u001b[0m     args_pos, args_rest \u001b[38;5;241m=\u001b[39m args_all[:n_positional], args_all[n_positional:]\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\readwrite.py:129\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m filename \u001b[38;5;241m=\u001b[39m Path(filename)  \u001b[38;5;66;03m# allow passing strings\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_valid_filename(filename):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbacked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfirst_column_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_column_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackup_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackup_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_compression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# generate filename and read to dict\u001b[39;00m\n\u001b[0;32m    142\u001b[0m filekey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(filename)\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\scanpy\\readwrite.py:764\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5ad\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sheet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 764\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbacked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m         logg\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_io\\h5ad.py:261\u001b[0m, in \u001b[0;36mread_h5ad\u001b[1;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m read_dataframe(elem)\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(elem)\n\u001b[1;32m--> 261\u001b[0m adata \u001b[38;5;241m=\u001b[39m \u001b[43mread_dispatched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Backwards compat (should figure out which version)\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw.X\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\experimental\\_dispatch_io.py:48\u001b[0m, in \u001b[0;36mread_dispatched\u001b[1;34m(elem, callback)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manndata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_io\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _REGISTRY, Reader\n\u001b[0;32m     46\u001b[0m reader \u001b[38;5;241m=\u001b[39m Reader(_REGISTRY, callback\u001b[38;5;241m=\u001b[39mcallback)\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_elem\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_io\\utils.py:207\u001b[0m, in \u001b[0;36mreport_read_key_on_error.<locals>.func_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo element found in args.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    209\u001b[0m     path, key \u001b[38;5;241m=\u001b[39m _get_display_path(store)\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_io\\specs\\registry.py:256\u001b[0m, in \u001b[0;36mReader.read_elem\u001b[1;34m(self, elem, modifiers)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_func(elem)\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miospec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miospec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_io\\h5ad.py:245\u001b[0m, in \u001b[0;36mread_h5ad.<locals>.callback\u001b[1;34m(func, elem_name, elem, iospec)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcallback\u001b[39m(func, elem_name: \u001b[38;5;28mstr\u001b[39m, elem, iospec):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iospec\u001b[38;5;241m.\u001b[39mencoding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manndata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m AnnData(\n\u001b[0;32m    242\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[0;32m    243\u001b[0m                 \u001b[38;5;66;03m# This is covering up backwards compat in the anndata initializer\u001b[39;00m\n\u001b[0;32m    244\u001b[0m                 \u001b[38;5;66;03m# In most cases we should be able to call `func(elen[k])` instead\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m                 k: \u001b[43mread_dispatched\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m elem\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    247\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    248\u001b[0m             }\n\u001b[0;32m    249\u001b[0m         )\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m elem_name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/raw.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\experimental\\_dispatch_io.py:48\u001b[0m, in \u001b[0;36mread_dispatched\u001b[1;34m(elem, callback)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manndata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_io\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _REGISTRY, Reader\n\u001b[0;32m     46\u001b[0m reader \u001b[38;5;241m=\u001b[39m Reader(_REGISTRY, callback\u001b[38;5;241m=\u001b[39mcallback)\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_elem\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_io\\utils.py:207\u001b[0m, in \u001b[0;36mreport_read_key_on_error.<locals>.func_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo element found in args.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    209\u001b[0m     path, key \u001b[38;5;241m=\u001b[39m _get_display_path(store)\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_io\\specs\\registry.py:256\u001b[0m, in \u001b[0;36mReader.read_elem\u001b[1;34m(self, elem, modifiers)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_func(elem)\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miospec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miospec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_io\\h5ad.py:259\u001b[0m, in \u001b[0;36mread_h5ad.<locals>.callback\u001b[1;34m(func, elem_name, elem, iospec)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/var\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# Backwards compat\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m read_dataframe(elem)\n\u001b[1;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_io\\specs\\methods.py:378\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(elem, _reader)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;129m@_REGISTRY\u001b[39m\u001b[38;5;241m.\u001b[39mregister_read(H5Array, IOSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    375\u001b[0m \u001b[38;5;129m@_REGISTRY\u001b[39m\u001b[38;5;241m.\u001b[39mregister_read(ZarrArray, IOSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    376\u001b[0m \u001b[38;5;129m@_REGISTRY\u001b[39m\u001b[38;5;241m.\u001b[39mregister_read(ZarrArray, IOSpec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring-array\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_array\u001b[39m(elem, _reader):\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43melem\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\h5py\\_hl\\dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "File \u001b[1;32mh5py\\_selector.pyx:368\u001b[0m, in \u001b[0;36mh5py._selector.Reader.read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_selector.pyx:342\u001b[0m, in \u001b[0;36mh5py._selector.Reader.make_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.24 GiB for an array with shape (9647, 34546) and data type float32",
      "\u001b[0mError raised while reading key 'X' of <class 'h5py._hl.dataset.Dataset'> from /"
     ]
    }
   ],
   "source": [
    "# Later, you can concatenate the batches\n",
    "batches = [sc.read(os.path.join(output_dir, f)) for f in os.listdir(output_dir) if f.endswith('.h5ad')]\n",
    "adata = sc.concat(batches)\n",
    "sc.pp.filter_genes(adata, min_cells=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sequential Processing with Incremental Merging: Instead of loading all .h5ad files at once, process them one by one or in smaller groups, then combine the results incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch_0.h5ad...\n",
      "Processing batch_1.h5ad...\n",
      "Processing batch_2.h5ad...\n",
      "Processing batch_3.h5ad...\n",
      "Processing batch_4.h5ad...\n",
      "Processing batch_5.h5ad...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.08 GiB for an array with shape (55051, 34546) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     merged_adata \u001b[38;5;241m=\u001b[39m adata\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     merged_adata \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmerged_adata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m adata\n\u001b[0;32m     15\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_core\\merge.py:1298\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;66;03m# Annotation for other axis\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m alt_annot \u001b[38;5;241m=\u001b[39m merge_dataframes(\n\u001b[0;32m   1295\u001b[0m     [\u001b[38;5;28mgetattr\u001b[39m(a, alt_dim) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m adatas], alt_indices, merge\n\u001b[0;32m   1296\u001b[0m )\n\u001b[1;32m-> 1298\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_Xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43madatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m join \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1301\u001b[0m     concat_aligned_mapping \u001b[38;5;241m=\u001b[39m inner_concat_aligned_mapping\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_core\\merge.py:1048\u001b[0m, in \u001b[0;36mconcat_Xs\u001b[1;34m(adatas, reindexers, axis, fill_value)\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome (but not all) of the AnnData\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms to be concatenated had no .X value. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcatenation is currently only implemented for cases where all or none of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the AnnData\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms have .X assigned.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1048\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcat_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\agarc\\anaconda3\\envs\\bioenv\\Lib\\site-packages\\anndata\\_core\\merge.py:826\u001b[0m, in \u001b[0;36mconcat_arrays\u001b[1;34m(arrays, reindexers, axis, index, fill_value)\u001b[0m\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sparse_stack(\n\u001b[0;32m    819\u001b[0m         [\n\u001b[0;32m    820\u001b[0m             f(as_sparse(a), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m axis, fill_value\u001b[38;5;241m=\u001b[39mfill_value)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    823\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    824\u001b[0m     )\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.08 GiB for an array with shape (55051, 34546) and data type float32"
     ]
    }
   ],
   "source": [
    "output_dir = 'D:/processed_batches/'\n",
    "merged_adata = None\n",
    "\n",
    "for file in os.listdir(output_dir):\n",
    "    if file.endswith('.h5ad'):\n",
    "        print(f\"Processing {file}...\")\n",
    "        adata = sc.read(os.path.join(output_dir, file))\n",
    "        \n",
    "        if merged_adata is None:\n",
    "            merged_adata = adata\n",
    "        else:\n",
    "            merged_adata = sc.concat([merged_adata, adata])\n",
    "        \n",
    "        del adata\n",
    "        gc.collect()\n",
    "\n",
    "# Save the final merged AnnData object\n",
    "merged_adata.write(os.path.join(output_dir, 'merged_data.h5ad'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(merged_adata, min_cells=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
